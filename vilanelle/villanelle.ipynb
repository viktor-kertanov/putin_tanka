{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATIVE VILLANELLE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wystan Hugh Auden \n",
    "\n",
    "**If I Could Tell You**\n",
    "\n",
    "Time will say nothing but I told you so,  \n",
    "Time only knows the price we have to pay;  \n",
    "If I could tell you I would let you know.  \n",
    "  \n",
    "If we should weep when clowns put on their show,  \n",
    "If we should stumble when musicians play,  \n",
    "Time will say nothing but I told you so.  \n",
    "\n",
    "There are no fortunes to be told, although,  \n",
    "Because I love you more than I can say,  \n",
    "If I could tell you I would let you know.  \n",
    "\n",
    "The winds must come from somewhere when they blow,  \n",
    "There must be reasons why the leaves decay;  \n",
    "Time will say nothing but I told you so.  \n",
    "  \n",
    "Perhaps the roses really want to grow,  \n",
    "The vision seriously intends to stay;  \n",
    "If I could tell you I would let you know.  \n",
    "  \n",
    "Suppose all the lions get up and go,  \n",
    "And all the brooks and soldiers run away;  \n",
    "Will Time say nothing but I told you so?  \n",
    "If I could tell you I would let you know.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syllable structure by line\n",
    "\n",
    "1. 10; u/u/u/u/u/\n",
    "2. 10; u/u/u/u/u/\n",
    "3. 10; u/u/u/u/u/\n",
    "\n",
    "4. 10; u/u/u/u/u/\n",
    "5. 10; u/u/u/u/u/\n",
    "6. 10; u/u/u/u/u/\n",
    "\n",
    "7. 10; u/u/u/u/u/\n",
    "8. 10; u/u/u/u/u/\n",
    "9. 10; u/u/u/u/u/\n",
    "\n",
    "10. 10; u/u/u/u/u/\n",
    "11. 10; u/u/u/u/u/\n",
    "12. 10; u/u/u/u/u/\n",
    "\n",
    "13. 10;\n",
    "14. 10;\n",
    "15. 10;\n",
    "\n",
    "16. 10;\n",
    "17. 10;\n",
    "18. 10;\n",
    "19. 10.\n",
    "\n",
    "Note: each line consists of 10 syllables strictly. 5-stanza iambic pentameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time will say nothing but i told you so,\n",
      "time only knows the price we have to pay;\n",
      "if i could tell you i would let you know.\n",
      "\n",
      "if we should weep when clowns put on their show,\n",
      "if we should stumble when musicians play,\n",
      "time will say nothing but i told you so.\n",
      "there are no fortunes to be told, although,\n",
      "because i love you more than i can say,\n",
      "if i could tell you i would let you know.\n",
      "the winds must come from somewhere when they blow,\n",
      "there must be reasons why the leaves decay;\n",
      "time will say nothing but i told you so.\n",
      "\n",
      "perhaps the roses really want to grow,\n",
      "the vision seriously intends to stay;\n",
      "if i could tell you i would let you know.\n",
      "\n",
      "suppose all the lions get up and go,\n",
      "and all the brooks and soldiers run away;\n",
      "will time say nothing but i told you so?\n",
      "if i could tell you i would let you know.\n"
     ]
    }
   ],
   "source": [
    "auden = \"\"\"\n",
    "Time will say nothing but I told you so,  \n",
    "Time only knows the price we have to pay;  \n",
    "If I could tell you I would let you know.  \n",
    "  \n",
    "If we should weep when clowns put on their show,  \n",
    "If we should stumble when musicians play,  \n",
    "Time will say nothing but I told you so.  \n",
    "\n",
    "There are no fortunes to be told, although,  \n",
    "Because I love you more than I can say,  \n",
    "If I could tell you I would let you know.  \n",
    "\n",
    "The winds must come from somewhere when they blow,  \n",
    "There must be reasons why the leaves decay;  \n",
    "Time will say nothing but I told you so.  \n",
    "  \n",
    "Perhaps the roses really want to grow,  \n",
    "The vision seriously intends to stay;  \n",
    "If I could tell you I would let you know.  \n",
    "  \n",
    "Suppose all the lions get up and go,  \n",
    "And all the brooks and soldiers run away;  \n",
    "Will Time say nothing but I told you so?  \n",
    "If I could tell you I would let you know.  \n",
    "\"\"\"\n",
    "lines = auden.split('\\n')\n",
    "lines = [el.lower().strip() for el in lines if el]\n",
    "for el in lines:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization of each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: ['time', 'will', 'say', 'nothing', 'but', 'i', 'told', 'you', 'so', ',']\n",
      "Line 2: ['time', 'only', 'knows', 'the', 'price', 'we', 'have', 'to', 'pay', ';']\n",
      "Line 3: ['if', 'i', 'could', 'tell', 'you', 'i', 'would', 'let', 'you', 'know', '.']\n",
      "Line 4: []\n",
      "Line 5: ['if', 'we', 'should', 'weep', 'when', 'clowns', 'put', 'on', 'their', 'show', ',']\n",
      "Line 6: ['if', 'we', 'should', 'stumble', 'when', 'musicians', 'play', ',']\n",
      "Line 7: ['time', 'will', 'say', 'nothing', 'but', 'i', 'told', 'you', 'so', '.']\n",
      "Line 8: ['there', 'are', 'no', 'fortunes', 'to', 'be', 'told', ',', 'although', ',']\n",
      "Line 9: ['because', 'i', 'love', 'you', 'more', 'than', 'i', 'can', 'say', ',']\n",
      "Line 10: ['if', 'i', 'could', 'tell', 'you', 'i', 'would', 'let', 'you', 'know', '.']\n",
      "Line 11: ['the', 'winds', 'must', 'come', 'from', 'somewhere', 'when', 'they', 'blow', ',']\n",
      "Line 12: ['there', 'must', 'be', 'reasons', 'why', 'the', 'leaves', 'decay', ';']\n",
      "Line 13: ['time', 'will', 'say', 'nothing', 'but', 'i', 'told', 'you', 'so', '.']\n",
      "Line 14: []\n",
      "Line 15: ['perhaps', 'the', 'roses', 'really', 'want', 'to', 'grow', ',']\n",
      "Line 16: ['the', 'vision', 'seriously', 'intends', 'to', 'stay', ';']\n",
      "Line 17: ['if', 'i', 'could', 'tell', 'you', 'i', 'would', 'let', 'you', 'know', '.']\n",
      "Line 18: []\n",
      "Line 19: ['suppose', 'all', 'the', 'lions', 'get', 'up', 'and', 'go', ',']\n",
      "Line 20: ['and', 'all', 'the', 'brooks', 'and', 'soldiers', 'run', 'away', ';']\n",
      "Line 21: ['will', 'time', 'say', 'nothing', 'but', 'i', 'told', 'you', 'so', '?']\n",
      "Line 22: ['if', 'i', 'could', 'tell', 'you', 'i', 'would', 'let', 'you', 'know', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Initialize the Spacy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")  # or \"en_core_web_lg\" for the large model\n",
    "\n",
    "# Sample lines from the poem\n",
    "\n",
    "# Convert lines to lowercase\n",
    "lines = [line.lower().strip() for line in lines]\n",
    "\n",
    "# Tokenize each line\n",
    "tokenized_lines = []\n",
    "for line in lines:\n",
    "    doc = nlp(line)\n",
    "    tokens = [token.text for token in doc]\n",
    "    tokenized_lines.append(tokens)\n",
    "\n",
    "# Display the tokenized lines\n",
    "for i, tokens in enumerate(tokenized_lines):\n",
    "    print(f\"Line {i+1}: {tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FREQUENCY COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies:\n",
      "time: 5\n",
      "will: 4\n",
      "say: 5\n",
      "nothing: 4\n",
      "but: 4\n",
      "i: 14\n",
      "told: 5\n",
      "you: 13\n",
      "so: 4\n",
      ",: 9\n",
      "only: 1\n",
      "knows: 1\n",
      "the: 7\n",
      "price: 1\n",
      "we: 3\n",
      "have: 1\n",
      "to: 4\n",
      "pay: 1\n",
      ";: 4\n",
      "if: 6\n",
      "could: 4\n",
      "tell: 4\n",
      "would: 4\n",
      "let: 4\n",
      "know: 4\n",
      ".: 6\n",
      "should: 2\n",
      "weep: 1\n",
      "when: 3\n",
      "clowns: 1\n",
      "put: 1\n",
      "on: 1\n",
      "their: 1\n",
      "show: 1\n",
      "stumble: 1\n",
      "musicians: 1\n",
      "play: 1\n",
      "there: 2\n",
      "are: 1\n",
      "no: 1\n",
      "fortunes: 1\n",
      "be: 2\n",
      "although: 1\n",
      "because: 1\n",
      "love: 1\n",
      "more: 1\n",
      "than: 1\n",
      "can: 1\n",
      "winds: 1\n",
      "must: 2\n",
      "come: 1\n",
      "from: 1\n",
      "somewhere: 1\n",
      "they: 1\n",
      "blow: 1\n",
      "reasons: 1\n",
      "why: 1\n",
      "leaves: 1\n",
      "decay: 1\n",
      "perhaps: 1\n",
      "roses: 1\n",
      "really: 1\n",
      "want: 1\n",
      "grow: 1\n",
      "vision: 1\n",
      "seriously: 1\n",
      "intends: 1\n",
      "stay: 1\n",
      "suppose: 1\n",
      "all: 2\n",
      "lions: 1\n",
      "get: 1\n",
      "up: 1\n",
      "and: 3\n",
      "go: 1\n",
      "brooks: 1\n",
      "soldiers: 1\n",
      "run: 1\n",
      "away: 1\n",
      "?: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Continue from the previous code\n",
    "# We already have 'tokenized_lines' containing the words of each line\n",
    "\n",
    "# Flatten the list of tokenized lines to get a list of all words\n",
    "all_words = [word for tokens in tokenized_lines for word in tokens]\n",
    "\n",
    "# Count the frequency of each unique word\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Display the word frequencies\n",
    "print(\"Word Frequencies:\")\n",
    "for word, freq in word_freq.items():\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS: PART OF SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: [('time', 'NOUN'), ('will', 'AUX'), ('say', 'VERB'), ('nothing', 'PRON'), ('but', 'CCONJ'), ('i', 'PRON'), ('told', 'VERB'), ('you', 'PRON'), ('so', 'ADV'), (',', 'PUNCT')]\n",
      "Line 2: [('time', 'NOUN'), ('only', 'ADV'), ('knows', 'VERB'), ('the', 'DET'), ('price', 'NOUN'), ('we', 'PRON'), ('have', 'VERB'), ('to', 'PART'), ('pay', 'VERB'), (';', 'PUNCT')]\n",
      "Line 3: [('if', 'SCONJ'), ('i', 'PRON'), ('could', 'AUX'), ('tell', 'VERB'), ('you', 'PRON'), ('i', 'PRON'), ('would', 'AUX'), ('let', 'VERB'), ('you', 'PRON'), ('know', 'VERB'), ('.', 'PUNCT')]\n",
      "Line 4: []\n",
      "Line 5: [('if', 'SCONJ'), ('we', 'PRON'), ('should', 'AUX'), ('weep', 'VERB'), ('when', 'SCONJ'), ('clowns', 'NOUN'), ('put', 'VERB'), ('on', 'ADP'), ('their', 'PRON'), ('show', 'NOUN'), (',', 'PUNCT')]\n",
      "Line 6: [('if', 'SCONJ'), ('we', 'PRON'), ('should', 'AUX'), ('stumble', 'VERB'), ('when', 'SCONJ'), ('musicians', 'NOUN'), ('play', 'VERB'), (',', 'PUNCT')]\n",
      "Line 7: [('time', 'NOUN'), ('will', 'AUX'), ('say', 'VERB'), ('nothing', 'PRON'), ('but', 'CCONJ'), ('i', 'PRON'), ('told', 'VERB'), ('you', 'PRON'), ('so', 'ADV'), ('.', 'PUNCT')]\n",
      "Line 8: [('there', 'PRON'), ('are', 'VERB'), ('no', 'DET'), ('fortunes', 'NOUN'), ('to', 'PART'), ('be', 'AUX'), ('told', 'VERB'), (',', 'PUNCT'), ('although', 'SCONJ'), (',', 'PUNCT')]\n",
      "Line 9: [('because', 'SCONJ'), ('i', 'PRON'), ('love', 'VERB'), ('you', 'PRON'), ('more', 'ADV'), ('than', 'SCONJ'), ('i', 'PRON'), ('can', 'AUX'), ('say', 'VERB'), (',', 'PUNCT')]\n",
      "Line 10: [('if', 'SCONJ'), ('i', 'PRON'), ('could', 'AUX'), ('tell', 'VERB'), ('you', 'PRON'), ('i', 'PRON'), ('would', 'AUX'), ('let', 'VERB'), ('you', 'PRON'), ('know', 'VERB'), ('.', 'PUNCT')]\n",
      "Line 11: [('the', 'DET'), ('winds', 'NOUN'), ('must', 'AUX'), ('come', 'VERB'), ('from', 'ADP'), ('somewhere', 'ADV'), ('when', 'SCONJ'), ('they', 'PRON'), ('blow', 'VERB'), (',', 'PUNCT')]\n",
      "Line 12: [('there', 'PRON'), ('must', 'AUX'), ('be', 'AUX'), ('reasons', 'NOUN'), ('why', 'SCONJ'), ('the', 'DET'), ('leaves', 'NOUN'), ('decay', 'VERB'), (';', 'PUNCT')]\n",
      "Line 13: [('time', 'NOUN'), ('will', 'AUX'), ('say', 'VERB'), ('nothing', 'PRON'), ('but', 'CCONJ'), ('i', 'PRON'), ('told', 'VERB'), ('you', 'PRON'), ('so', 'ADV'), ('.', 'PUNCT')]\n",
      "Line 14: []\n",
      "Line 15: [('perhaps', 'ADV'), ('the', 'DET'), ('roses', 'NOUN'), ('really', 'ADV'), ('want', 'VERB'), ('to', 'PART'), ('grow', 'VERB'), (',', 'PUNCT')]\n",
      "Line 16: [('the', 'DET'), ('vision', 'NOUN'), ('seriously', 'ADV'), ('intends', 'VERB'), ('to', 'PART'), ('stay', 'VERB'), (';', 'PUNCT')]\n",
      "Line 17: [('if', 'SCONJ'), ('i', 'PRON'), ('could', 'AUX'), ('tell', 'VERB'), ('you', 'PRON'), ('i', 'PRON'), ('would', 'AUX'), ('let', 'VERB'), ('you', 'PRON'), ('know', 'VERB'), ('.', 'PUNCT')]\n",
      "Line 18: []\n",
      "Line 19: [('suppose', 'VERB'), ('all', 'DET'), ('the', 'DET'), ('lions', 'NOUN'), ('get', 'VERB'), ('up', 'ADP'), ('and', 'CCONJ'), ('go', 'VERB'), (',', 'PUNCT')]\n",
      "Line 20: [('and', 'CCONJ'), ('all', 'DET'), ('the', 'DET'), ('brooks', 'NOUN'), ('and', 'CCONJ'), ('soldiers', 'NOUN'), ('run', 'VERB'), ('away', 'ADV'), (';', 'PUNCT')]\n",
      "Line 21: [('will', 'AUX'), ('time', 'NOUN'), ('say', 'VERB'), ('nothing', 'PRON'), ('but', 'CCONJ'), ('i', 'PRON'), ('told', 'VERB'), ('you', 'PRON'), ('so', 'ADV'), ('?', 'PUNCT')]\n",
      "Line 22: [('if', 'SCONJ'), ('i', 'PRON'), ('could', 'AUX'), ('tell', 'VERB'), ('you', 'PRON'), ('i', 'PRON'), ('would', 'AUX'), ('let', 'VERB'), ('you', 'PRON'), ('know', 'VERB'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "# Continue from the previous code\n",
    "# We have 'tokenized_lines' and Spacy's 'nlp' already initialized\n",
    "\n",
    "# Tag each line for parts of speech\n",
    "tagged_lines = []\n",
    "for line in lines:\n",
    "    doc = nlp(line)\n",
    "    tagged_line = [(token.text, token.pos_) for token in doc]\n",
    "    tagged_lines.append(tagged_line)\n",
    "\n",
    "# Display the POS-tagged lines\n",
    "for i, tagged_tokens in enumerate(tagged_lines):\n",
    "    print(f\"Line {i+1}: {tagged_tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Spacy's part-of-speech tagging, `CCONJ` stands for \"Coordinating Conjunction.\" Coordinating conjunctions are words that join together elements of the same kind. In English, the coordinating conjunctions are often remembered by the acronym FANBOYS, which stands for:\n",
    "\n",
    "- For\n",
    "- And\n",
    "- Nor\n",
    "- But\n",
    "- Or\n",
    "- Yet\n",
    "- So\n",
    "\n",
    "These words can join two nouns, two verbs, two adjectives, two phrases, or two independent clauses. For example, in the sentence \"I like apples and oranges,\" the word \"and\" is a coordinating conjunction that joins together the nouns \"apples\" and \"oranges.\"\n",
    "\n",
    "Understanding the role of each part-of-speech, including conjunctions like `CCONJ`, can help in structuring generated text in a grammatically correct way.\n",
    "\n",
    "Would you like to continue to the next step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SCONJ tag in Spacy stands for \"Subordinating Conjunction.\" Subordinating conjunctions are used to join an independent clause and a dependent clause. Unlike coordinating conjunctions, which connect equal parts of a sentence, subordinating conjunctions are used to indicate that one clause is subordinate to, or dependent on, another.\n",
    "\n",
    "Common examples of subordinating conjunctions in English include:\n",
    "\n",
    "Although\n",
    "Because\n",
    "Since\n",
    "While\n",
    "If\n",
    "Unless\n",
    "Even though\n",
    "As soon as\n",
    "For example, in the sentence \"Although it was raining, they went for a hike,\" the word \"Although\" is a subordinating conjunction that joins the dependent clause \"it was raining\" with the independent clause \"they went for a hike.\"\n",
    "\n",
    "Understanding subordinating conjunctions can be useful in generating complex sentences that have depth, thereby making your generated poetry more nuanced.\n",
    "\n",
    "Would you like to proceed to the next step?\n",
    "\n",
    "The 10 most frequent SCONJ lemmas: that, if, as, because, for, of, since, before, like, after, than\n",
    "\n",
    "https://universaldependencies.org/docs/en/pos/SCONJ.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common bigrams:\n",
      "say nothing: 4\n",
      "nothing but: 4\n",
      "but i: 4\n",
      "i told: 4\n",
      "told you: 4\n",
      "you so: 4\n",
      "if i: 4\n",
      "i could: 4\n",
      "could tell: 4\n",
      "tell you: 4\n",
      "you i: 4\n",
      "i would: 4\n",
      "would let: 4\n",
      "let you: 4\n",
      "you know: 4\n",
      "know .: 4\n",
      "time will: 3\n",
      "will say: 3\n",
      "if we: 2\n",
      "we should: 2\n",
      "\n",
      "Most common trigrams:\n",
      "say nothing but: 4\n",
      "nothing but i: 4\n",
      "but i told: 4\n",
      "i told you: 4\n",
      "told you so: 4\n",
      "if i could: 4\n",
      "i could tell: 4\n",
      "could tell you: 4\n",
      "tell you i: 4\n",
      "you i would: 4\n",
      "i would let: 4\n",
      "would let you: 4\n",
      "let you know: 4\n",
      "you know .: 4\n",
      "time will say: 3\n",
      "will say nothing: 3\n",
      "if we should: 2\n",
      "you so .: 2\n",
      "you so ,: 1\n",
      "time only knows: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Continue from previous code where we have 'tokenized_lines'\n",
    "\n",
    "# Function to generate n-grams from tokens\n",
    "def generate_ngrams(tokens, n):\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "# Generate bigrams and trigrams for each line\n",
    "bigrams = []\n",
    "trigrams = []\n",
    "for tokens in tokenized_lines:\n",
    "    bigrams.extend(generate_ngrams(tokens, 2))\n",
    "    trigrams.extend(generate_ngrams(tokens, 3))\n",
    "\n",
    "# Count frequency of each bigram and trigram\n",
    "bigram_freq = Counter(bigrams)\n",
    "trigram_freq = Counter(trigrams)\n",
    "\n",
    "# Display the most common bigrams and trigrams\n",
    "print(\"Most common bigrams:\")\n",
    "for bigram, freq in bigram_freq.most_common(20):\n",
    "    print(f\"{bigram}: {freq}\")\n",
    "\n",
    "print(\"\\nMost common trigrams:\")\n",
    "for trigram, freq in trigram_freq.most_common(20):\n",
    "    print(f\"{trigram}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pos(tagged_lines: list[list]):\n",
    "    unique_pos = set()\n",
    "    for line in tagged_lines:\n",
    "        for word in line:\n",
    "            unique_pos.add(word[1])\n",
    "    \n",
    "    return unique_pos\n",
    "\n",
    "def get_unique_pos(pos: str, tagged_lines: list[list]) -> set[str]:\n",
    "    pos_collection = set()\n",
    "    for line in tagged_lines:\n",
    "        for word in line:\n",
    "            if word[1] == pos.upper().strip():\n",
    "                pos_collection.add(word[0])\n",
    "    \n",
    "    return pos_collection\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come\n",
      "know\n",
      "go\n",
      "grow\n",
      "stay\n",
      "get\n",
      "want\n",
      "intends\n",
      "say\n",
      "put\n",
      "run\n",
      "let\n",
      "told\n",
      "are\n",
      "decay\n",
      "stumble\n",
      "love\n",
      "blow\n",
      "suppose\n",
      "play\n",
      "have\n",
      "knows\n",
      "weep\n",
      "tell\n",
      "pay\n"
     ]
    }
   ],
   "source": [
    "unique_pos = get_all_pos(tagged_lines)\n",
    "\n",
    "nouns = get_unique_pos('VERB', tagged_lines)\n",
    "for el in nouns:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1 Sentiment: 0.00. Line: time will say nothing but i told you so,\n",
      "Line 2 Sentiment: 0.00. Line: time only knows the price we have to pay;\n",
      "Line 3 Sentiment: 0.00. Line: if i could tell you i would let you know.\n",
      "Line 4 Sentiment: 0.00. Line: \n",
      "Line 5 Sentiment: 0.00. Line: if we should weep when clowns put on their show,\n",
      "Line 6 Sentiment: -0.05. Line: if we should stumble when musicians play,\n",
      "Line 7 Sentiment: 0.00. Line: time will say nothing but i told you so.\n",
      "Line 8 Sentiment: 0.00. Line: there are no fortunes to be told, although,\n",
      "Line 9 Sentiment: 0.50. Line: because i love you more than i can say,\n",
      "Line 10 Sentiment: 0.00. Line: if i could tell you i would let you know.\n",
      "Line 11 Sentiment: 0.00. Line: the winds must come from somewhere when they blow,\n",
      "Line 12 Sentiment: 0.00. Line: there must be reasons why the leaves decay;\n",
      "Line 13 Sentiment: 0.00. Line: time will say nothing but i told you so.\n",
      "Line 14 Sentiment: 0.00. Line: \n",
      "Line 15 Sentiment: 0.20. Line: perhaps the roses really want to grow,\n",
      "Line 16 Sentiment: -0.33. Line: the vision seriously intends to stay;\n",
      "Line 17 Sentiment: 0.00. Line: if i could tell you i would let you know.\n",
      "Line 18 Sentiment: 0.00. Line: \n",
      "Line 19 Sentiment: 0.00. Line: suppose all the lions get up and go,\n",
      "Line 20 Sentiment: 0.00. Line: and all the brooks and soldiers run away;\n",
      "Line 21 Sentiment: 0.00. Line: will time say nothing but i told you so?\n",
      "Line 22 Sentiment: 0.00. Line: if i could tell you i would let you know.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Continue from previous code where we have 'lines' containing each line of the poem\n",
    "\n",
    "# Perform sentiment analysis on each line\n",
    "sentiment_lines = []\n",
    "for line in lines:\n",
    "    blob = TextBlob(line)\n",
    "    sentiment = blob.sentiment.polarity  # -1 to 1: Negative to Positive\n",
    "    sentiment_lines.append(sentiment)\n",
    "\n",
    "# Display the sentiment of each line\n",
    "for i, sentiment in enumerate(sentiment_lines):\n",
    "    print(f\"Line {i+1} Sentiment: {sentiment:.2f}. Line: {lines[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1 Entities: []\n",
      "Line 2 Entities: []\n",
      "Line 3 Entities: []\n",
      "Line 4 Entities: []\n",
      "Line 5 Entities: []\n",
      "Line 6 Entities: []\n",
      "Line 7 Entities: []\n",
      "Line 8 Entities: []\n",
      "Line 9 Entities: []\n",
      "Line 10 Entities: []\n",
      "Line 11 Entities: []\n",
      "Line 12 Entities: []\n",
      "Line 13 Entities: []\n",
      "Line 14 Entities: []\n",
      "Line 15 Entities: []\n",
      "Line 16 Entities: []\n",
      "Line 17 Entities: []\n",
      "Line 18 Entities: []\n",
      "Line 19 Entities: []\n",
      "Line 20 Entities: []\n",
      "Line 21 Entities: []\n",
      "Line 22 Entities: []\n"
     ]
    }
   ],
   "source": [
    "# Perform NER on each line\n",
    "ner_lines = []\n",
    "for line in lines:\n",
    "    doc = nlp(line)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    ner_lines.append(entities)\n",
    "\n",
    "# Display the named entities for each line\n",
    "for i, entities in enumerate(ner_lines):a\n",
    "    print(f\"Line {i+1} Entities: {entities}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
